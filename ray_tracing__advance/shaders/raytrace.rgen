/*
 * Copyright (c) 2019-2021, NVIDIA CORPORATION.  All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 *
 * SPDX-FileCopyrightText: Copyright (c) 2019-2021 NVIDIA CORPORATION
 * SPDX-License-Identifier: Apache-2.0
 */

#version 460
#extension GL_EXT_ray_tracing : require
#extension GL_GOOGLE_include_directive : enable
#extension GL_EXT_shader_explicit_arithmetic_types_int64 : require
#extension GL_EXT_scalar_block_layout : require

#include "random.glsl"
#include "raycommon.glsl"
#include "wavefront.glsl"

// clang-format off
layout(location = 0) rayPayloadEXT hitPayload prd;

layout(set = 0, binding = eTlas) uniform accelerationStructureEXT topLevelAS;
layout(set = 0, binding = eOutImage, rgba32f) uniform image2D image;
layout(set = 1, binding = eGlobals) uniform _GlobalUniforms { GlobalUniforms uni; };
layout(push_constant) uniform _PushConstantRay { PushConstantRay pcRay; };
// clang-format on

//  
layout(std430, set = 1, binding = eAtrInfo) uniform _AtrInfoUniforms { AtrInfo ai; };
layout(set = 1, binding = eAtrSamplerLinear) uniform sampler AtrSampLin;
layout(set = 1, binding = eAtrTexture) uniform texture3D atrTexture;
layout(set = 1, binding = eColormapTexture) uniform texture1D colormapTexture;
layout(location = 3) callableDataEXT rayLight cLight;


const int NBSAMPLES = 1;

vec4 mapColormap (float value);
vec3 calculateNormal (vec3 normalizedCoord);
vec3 computeDiffuseLighting(vec3 normal, vec3 cameraPosition, vec3 worldPosition);
mat3 calculateTransform(vec3 N);
void render3dUIObjects(vec3 rayOrigin, vec3 rayDirection);
vec3 refineISOSurface(vec3 rayOrigin, vec3 rayDirection, float stepSize, vec3 p, float t);

#define ENABLED_ISOVALUE                      0
//#define ENABLED_REFINEMENT         (1 && ENABLED_ISOVALUE)
#define ENABLED_DVR                (1 && !ENABLED_ISOVALUE)

#define ENABLED_DEBUG_AMBIENT_OCCLUSION       0


vec4 planeColor;

void main()
{
    // Initialize the random number
    uint seed = tea(gl_LaunchIDEXT.y * gl_LaunchSizeEXT.x + gl_LaunchIDEXT.x, pcRay.frame * NBSAMPLES);
    prd.seed  = seed;

    vec3 normal = vec3(0.f);
    prd.done                = 1;      
    prd.depth               = 0;
    prd.hitValue            = vec4(0.f, 0.f, 0.f ,0.f);
    prd.attenuation         = vec4(1.f, 1.f, 1.f, 1.f);
    prd.lastT               = -1.f;
    prd.hitCount            = 0;

    vec4 finalColor = vec4(0);
    float finalAO = 0;

    for(int smpl = 0; smpl < NBSAMPLES; smpl++)
    {
        float r1 = rnd(seed);
        float r2 = rnd(seed);
        // Subpixel jitter: send the ray through a different position inside the pixel
        // each time, to provide antialiasing.
        vec2 subpixel_jitter    = pcRay.frame == 0 ? vec2(0.5f, 0.5f) : vec2(r1, r2);        
        const vec2 pixelCenter  = vec2(gl_LaunchIDEXT.xy) + subpixel_jitter;        
        const vec2 inUV         = pixelCenter / vec2(gl_LaunchSizeEXT.xy);
        vec2       d            = inUV * 2.0 - 1.0;
        
        vec4 origin             = uni.viewInverse * vec4(0, 0, 0, 1);
        vec4 target             = uni.projInverse * vec4(d.x, d.y, 1, 1);
        vec4 direction          = uni.viewInverse * vec4(normalize(target.xyz), 0);
        
        prd.rayOrigin           = origin.xyz;
        prd.rayDir              = direction.xyz;

//#if 0
        render3dUIObjects(origin.xyz, direction.xyz);
//

        vec3 minCorner = ai.minPoint.xyz;
        vec3 maxCorner = ai.minPoint.xyz + ai.dimension.xyz;
        
        // in which box side the ray from the origin enters and at which side exits
        vec3 s1, s2;
        vec3 n1 = vec3(-1.f, 0.f,  0.f);
        vec3 n2 = vec3( 0.f, -1.f,  0.f);
        vec3 n3 = vec3( 0.f,  0.f, -1.f);
        vec3 n4 = vec3( 1.f,  0.f,  0.f);
        vec3 n5 = vec3( 0.f,  1.f,  0.f);
        vec3 n6 = vec3( 0.f,  0.f,  1.f);
        
        float t1 = dot((minCorner - origin.xyz), n1) / dot (n1, direction.xyz);
        float t2 = dot((minCorner - origin.xyz), n2) / dot (n2, direction.xyz);
        float t3 = dot((minCorner - origin.xyz), n3) / dot (n3, direction.xyz);
        float t4 = dot((maxCorner - origin.xyz), n4) / dot (n4, direction.xyz);
        float t5 = dot((maxCorner - origin.xyz), n5) / dot (n5, direction.xyz);
        float t6 = dot((maxCorner - origin.xyz), n6) / dot (n6, direction.xyz);
        
        if(t1 > t4) { float tmp = t4; t4 = t1; t1 = tmp; }
        if(t2 > t5) { float tmp = t5; t5 = t2; t2 = tmp; }
        if(t3 > t6) { float tmp = t6; t6 = t3; t3 = tmp; }
    
        float tMin = max(t1, max(t2, t3));
        float tMax = min(t4, min(t5, t6));
       
         
    
        vec4 hitValues = vec4 (0);//pcRay.clearColor.xyz * 0.8, 1.f);
        float ao = 0.f;
       
        float tPlane = prd.tHit < 10000 ? prd.tHit : dot((ai.planePosition.xyz - origin.xyz), ai.planeNormal.xyz) / dot (ai.planeNormal.xyz, direction.xyz); // not missed 3d guide objects ? tHit of 3d objects : t (ray hits plane) = (P-O).N / N.D
        //tMax = min(tMax, tPlane);
        float planeSize = length(maxCorner - minCorner) * 1.5f;
        vec3 distanceToPlaneCenter = origin.xyz + tPlane * direction.xyz - ai.planePosition.xyz; // hit point distance to plane center
        bool ignoreRayTracing = false;
        
        vec3 entryPos = origin.xyz + tMin * direction.xyz;      // entry position of ray to 3d volume box
        vec3 exitPos = origin.xyz + tMax * direction.xyz;       // exit position of ray from 3d volume box
        
        float entryPosProj = dot(entryPos - ai.planePosition.xyz, ai.planeNormal.xyz);      // to see whether the volume is in front of clip plane or behind it, related to its normal
        float exitPosProj = dot(exitPos - ai.planePosition.xyz, ai.planeNormal.xyz);
        bool stopRay = false;

        // if both entry and exit points are on the side of the clip plane that 
        // should be clipped
        if(entryPosProj > 0 && exitPosProj > 0) {
            ignoreRayTracing = true;       
        }
        
        // if entry point is on the side of plane that should be clipped
        if(entryPosProj > 0)
            tMin = max(tMin, tPlane);   // means tMin = tPlane
        
        // if exit point is on the side of plane that should be clipped 
        if(exitPosProj > 0)
            tMax = min(tMax, tPlane);   // means tMax = tPlane
            
//        if(abs(length(distanceToPlaneCenter) - planeSize / 2) < 2) {    // show plane border
//            //ignoreRayTracing = true;
//            tMax = min(tMax, tPlane);
//            //hitValues = vec4 (1.f, 0.f, 0.f, 0.f);
//        }
    
//        if(length(distanceToPlaneCenter) < 2 && dot(distanceToPlaneCenter, ai.planeNormal.xyz) == 0) { // show normal
//            ignoreRayTracing = true;
//            hitValues = vec4 (0.f, 0.f, 1.f, 0.f);
//        }
        if(prd.tHit < 10000 && prd.tHit > 0 && prd.tHit < tMax)
        {
            vec4 C = prd.hitValue;
            float ain = hitValues.a;
            vec3 Cin = hitValues.rgb;
            hitValues.rgb = Cin + (1 - ain) * C.rgb;
            hitValues.a = 1;
            ignoreRayTracing = true;
        }

        bool doRayMarching = tMax > tMin && tMin > 0 && !ignoreRayTracing;
        
        if(doRayMarching) {
            float stepSize = 0.5f;// ai.ISOValue;//length(maxCorner - minCorner) / 400.f;//(tMax - tMin) / 100.f;
            float t = tMin;
            
            for(int i=0; i<500 && t < tMax; ++i , t += stepSize) {
                vec3 p = origin.xyz + t * direction.xyz;
                vec3 normalizedCoord = (p - ai.minPoint.xyz) / ai.dimension.xyz;
                            
                float attr = texture(sampler3D(atrTexture, AtrSampLin), normalizedCoord).x;
#if ENABLED_ISOVALUE
                if(attr >= ai.ISOValue) 
                {                    
                    if(ai.enableRefinement == 1) {
                        if(i > 0) {
                            normalizedCoord = refineISOSurface(origin.xyz, direction.xyz, stepSize, p, t);
                            attr = texture(sampler3D(atrTexture, AtrSampLin), normalizedCoord).x;
                        }
                    }
                    normal = calculateNormal(normalizedCoord);

                    if(ai.useAmbinetOcclusion[0] != 0)
                    {
                        mat3 tangentSpaceTransformation = calculateTransform(normal);   // normal space transformation

                        const int aoSampleCount = 16;

                        for(int d=0; d<aoSampleCount; ++d) {
                            vec3 dir = normalize(tangentSpaceTransformation * ai.randomDirections[d].xyz); // bring directions from world space to tanget space
                            if(false && dot(dir, normal) < 0) {
                                dir = -dir;
                            }
                            
                            for(int s=2; s<10; ++s) {   // s = 2: to avoid self intersections
                                vec3 p0 = p + dir * s * stepSize;       // 
                                normalizedCoord = (p0 - ai.minPoint.xyz) / ai.dimension.xyz;
                                float a = texture(sampler3D(atrTexture, AtrSampLin), normalizedCoord).x;
                                if(a >= ai.ISOValue) {       // occoluded
                                    ao += 1.f;
                                    break;
                                }
                            }
                        }
                        ao /= aoSampleCount; // non occuluded
                    }
                             
                    hitValues = mapColormap(attr);
                    break;
                }

#elif ENABLED_DVR
                normal = calculateNormal(normalizedCoord);
                
                if(ai.useAmbinetOcclusion[0] != 0)
                {
                    mat3 tangentSpaceTransformation = calculateTransform(normal);   // normal space transformation

                    const int aoSampleCount = 16;

                    for(int d=0; d<aoSampleCount; ++d) {
                        vec3 dir = normalize(tangentSpaceTransformation * ai.randomDirections[d].xyz); // bring directions from world space to tanget space
                        if(false && dot(dir, normal) < 0) {
                            dir = -dir;
                        }
                        float collectedOcclusion = 0.f;
                        for(int s=2; s<10; ++s) {   // s = 2: to avoid self intersections
                            vec3 p0 = p + dir * s * stepSize;       // 
                            
                            normalizedCoord = (p0 - ai.minPoint.xyz) / ai.dimension.xyz;
                            float atr = texture(sampler3D(atrTexture, AtrSampLin), normalizedCoord).x;
                                                            
                            // Front-to-back strategy
                            float a = mapColormap(atr).a;
                                                                                      
                            collectedOcclusion = collectedOcclusion + (1 - collectedOcclusion) * a;

                            if(collectedOcclusion >= .95f) {
                                break;
                            }
                        }
                        ao += collectedOcclusion; 
                    }
                    ao /= aoSampleCount; // non occluded
                }
                // ray tace
                vec3 diffuse = computeDiffuseLighting(normal, origin.xyz, p);
                
                vec3 ambientColor = vec3(1.f);
                float diffuseMultiplier = 0.9;
                float ambientMultiplier = 1.f;

                diffuse *= diffuseMultiplier;
                ambientColor *= ambientMultiplier; 
                diffuse += (1-ao) * ambientColor;
                // map colormap
                // Front-to-back strategy
                vec4 C = mapColormap(attr) * vec4(diffuse, 1.f); // C
                float a = C.a;
                float ain = hitValues.a;
                vec3 Cin = hitValues.rgb;
                hitValues.rgb = Cin + (1 - ain) * a * C.rgb;
                hitValues.a = ain + (1 - ain) * a;
                if(hitValues.a >= .95f) {
                    break;
                }
#endif // endif ENABLED_ISOVALUE/ENABLED_DVR
            } // end of raycasting for
        } // end of !ignoreRayTracing if

        if(prd.tHit < 10000 && (prd.tHit > tMin || !doRayMarching))
        {
            vec4 C = prd.hitValue;;
            float ain = hitValues.a;
            vec3 Cin = hitValues.rgb;
            hitValues.rgb = Cin + (1 - ain) * C.rgb;
            hitValues.a = 1;
        }

        // background color: clearColor
        vec4 C = vec4 (pcRay.clearColor.xyz * 0.8, 1.f);
        // float a = C.a; // a is 1.f;
        float ain = hitValues.a;
        vec3 Cin = hitValues.rgb;
        hitValues.rgb = Cin + (1 - ain) * C.rgb;
        hitValues.a = 1;
        
        finalColor += hitValues;
        finalAO += (1.0f - ao);
    }
    finalColor *= 1.f / NBSAMPLES;
    finalAO *= 1.f / NBSAMPLES;

    

#if !ENABLED_DVR
    // Diffuse
    vec3 diffuse = computeDiffuseLighting(normal, origin, p);
    //
    vec3 ambientColor = vec3(0.05, 0.05, 0.05);
    float diffuseMultiplier = 0.9;
    float ambientMultiplier = 0.5;

    diffuse *= diffuseMultiplier;
    ambientColor *= ambientMultiplier; 

    finalColor = vec4((1-finalAO) * ambientColor, 0) + finalColor * vec4(diffuse, 1.f);
#if ENABLED_DEBUG_AMBIENT_OCCLUSION
    finalColor = vec4(finalAO, finalAO, finalAO, 1);
#endif
#endif  
    // Do accumulation over time
    if(pcRay.frame >= 0)
    {
      float a         = 1.0f / float(pcRay.frame + 1);
      vec3  old_color = imageLoad(image, ivec2(gl_LaunchIDEXT.xy)).xyz;
      imageStore(image, ivec2(gl_LaunchIDEXT.xy), vec4(mix(old_color, finalColor.rgb, a), 1.f));
    }
    else
    {
      // First frame, replace the value in the buffer
      imageStore(image, ivec2(gl_LaunchIDEXT.xy), vec4(finalColor.rgb, 1.f));
    }    
}

vec4 mapColormap (float value) {
    float normalizedValue = (value - ai.minAtrValue) / (ai.maxAtrValue - ai.minAtrValue);
    vec4 color =  texture(sampler1D(colormapTexture, AtrSampLin), normalizedValue);
    return color;
}

vec3 calculateNormal (vec3 normalizedCoord) {
    //Computing normal with gradient of the surface
    vec3 normal;
    float f_XPlusDeltaX    = texture(sampler3D(atrTexture, AtrSampLin), clamp (normalizedCoord + vec3(1.0f/ai.dimension.x, 0.0f, 0.0f), 0.0f, 1.0f)).r;
    float f_XMinusDeltaX   = texture(sampler3D(atrTexture, AtrSampLin), clamp (normalizedCoord - vec3(1.0f/ai.dimension.x, 0.0f, 0.0f), 0.0f, 1.0f)).r;
    float f_YPlusDeltaY    = texture(sampler3D(atrTexture, AtrSampLin), clamp (normalizedCoord + vec3(0.0f, 1.0f/ai.dimension.y, 0.0f), 0.0f, 1.0f)).r;
    float f_YMinusDeltaY   = texture(sampler3D(atrTexture, AtrSampLin), clamp (normalizedCoord - vec3(0.0f, 1.0f/ai.dimension.y, 0.0f), 0.0f, 1.0f)).r;
    float f_ZPlusDeltaZ    = texture(sampler3D(atrTexture, AtrSampLin), clamp (normalizedCoord + vec3(0.0f, 0.0f, 1.0f/ai.dimension.z), 0.0f, 1.0f)).r;
    float f_ZMinusDeltaZ   = texture(sampler3D(atrTexture, AtrSampLin), clamp (normalizedCoord - vec3(0.0f, 0.0f, 1.0f/ai.dimension.z), 0.0f, 1.0f)).r;
    
    vec3 n = vec3 (f_XPlusDeltaX - f_XMinusDeltaX, f_YPlusDeltaY - f_YMinusDeltaY, f_ZPlusDeltaZ - f_ZMinusDeltaZ) * ai.dimension.xyz * 0.5f;
    if(dot(n, n) < 0.001f)    // |n^2| < 0.001f
        normal = vec3(0.0f);
    else
        normal = normalize(n);
    return normal;
}

vec3 computeDiffuseLighting(vec3 normal, vec3 cameraPosition, vec3 worldPosition) {
    // Point light
    if(pcRay.lightType == 0)
    {
      vec3  lDir              = pcRay.lightPosition - cLight.inHitPosition;
      float lightDistance     = length(lDir);
      cLight.outIntensity     = pcRay.lightIntensity / (lightDistance * lightDistance);
      cLight.outLightDir      = normalize(lDir);
      cLight.outLightDistance = lightDistance;
    }
    else if(pcRay.lightType == 1) // spot light
    {
      vec3 lDir               = pcRay.lightPosition - cLight.inHitPosition;
      cLight.outLightDistance = length(lDir);
      cLight.outIntensity     = pcRay.lightIntensity / (cLight.outLightDistance * cLight.outLightDistance);
      cLight.outLightDir      = normalize(lDir);
      float theta             = dot(cLight.outLightDir, normalize(-pcRay.lightDirection));
      float epsilon           = pcRay.lightSpotCutoff - pcRay.lightSpotOuterCutoff;
      float spotIntensity     = clamp((theta - pcRay.lightSpotOuterCutoff) / epsilon, 0.0, 1.0);
      cLight.outIntensity *= spotIntensity;
    }
    else  // Directional light
    {
      cLight.outLightDir      = normalize(-pcRay.lightDirection);
      cLight.outIntensity     = 1.0;
      cLight.outLightDistance = 10000000;
    }

    // headlight
    cLight.outLightDir      = normalize(cameraPosition - worldPosition);

    // Diffuse
    vec3 diffuse = length (normal) < 0.001 ? vec3(1.f) : computeDiffuse(cLight.outLightDir, normal);
    
    return diffuse * cLight.outIntensity;
}

mat3 calculateTransform(vec3 N)
{
  vec3 A = vec3(0.f, 1.f, 0.f);
  
  if(length(cross(A, N)) < 0.001f)
  {
    A = vec3(0.f, 0.0f, 1.0f);
  }

  vec3 X = cross(N, A);
  vec3 Y = cross(N, X);
  vec3 Z = N;

  X = normalize(X);
  Y = normalize(Y);
  Z = normalize(Z);

  //mat4 m0 = mat4(1.f);

  //m0.rotate(3.14159265f / 2.0f, vec3(1, 0, 0));

  //mat4 m1 = mat4(1.f);
  //m1.translate(P);


  mat3 m2 = mat3(vec3(X.x, Y.x, Z.x),
                 vec3(X.y, Y.y, Z.y),
                 vec3(X.z, Y.z, Z.z));
  m2 = transpose(m2);

  /* mat3 m2 = mat3(X,
                 Y,
                 Z);
   */
  //nvmath::mat4f mat2 = nvmath::mat4f(X.x, X.y, X.z, 0, Y.x, Y.y, Y.z, 0, Z.x, Z.y, Z.z, 0, 0, 0, 0, 1);
//  mat4 scale = mat4(1.f);
//  scale.scale(s);

  //mat4 m3 = m2 ;
  return m2;
}

void render3dUIObjects(vec3 rayOrigin, vec3 rayDirection) {
    uint  rayFlags = gl_RayFlagsNoOpaqueEXT;
    float tMin     = 0.001;
    float tMax     = 10000.0;
    traceRayEXT(topLevelAS,     // acceleration structure
                rayFlags,       // rayFlags
                0xFF,           // cullMask
                0,              // sbtRecordOffset
                0,              // sbtRecordStride
                0,              // missIndex
                rayOrigin,     // ray origin
                tMin,          // ray min range
                rayDirection,  // ray direction
                tMax,        // ray max range
                0               // payload (location = 0)
        );
}

vec3 refineISOSurface(vec3 rayOrigin, vec3 rayDirection, float stepSize, vec3 p, float t) {
    vec3 lastPos = rayOrigin + (t-stepSize) * rayDirection;
    for (int j=0; j<10; j++) {
        vec3 midPos = (p + lastPos)/2.f;
        vec3 normalizedCoord = (midPos - ai.minPoint.xyz) / ai.dimension.xyz;
        float attr = texture(sampler3D(atrTexture, AtrSampLin), normalizedCoord).x;
        if(attr >= ai.ISOValue) {
            p = midPos;
        } else {
            lastPos = midPos;
        }
    }
    return (p - ai.minPoint.xyz) / ai.dimension.xyz;
}