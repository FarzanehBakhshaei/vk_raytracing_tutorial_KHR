/*
 * Copyright (c) 2019-2021, NVIDIA CORPORATION.  All rights reserved.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 *
 * SPDX-FileCopyrightText: Copyright (c) 2019-2021 NVIDIA CORPORATION
 * SPDX-License-Identifier: Apache-2.0
 */

#version 460
#extension GL_EXT_ray_tracing : require
#extension GL_GOOGLE_include_directive : enable
#extension GL_EXT_shader_explicit_arithmetic_types_int64 : require
#extension GL_EXT_scalar_block_layout : require

#include "random.glsl"
#include "raycommon.glsl"
#include "wavefront.glsl"

// clang-format off
layout(location = 0) rayPayloadEXT hitPayload prd;

layout(set = 0, binding = eTlas) uniform accelerationStructureEXT topLevelAS;
layout(set = 0, binding = eOutImage, rgba32f) uniform image2D image;
layout(set = 1, binding = eGlobals) uniform _GlobalUniforms { GlobalUniforms uni; };
layout(push_constant) uniform _PushConstantRay { PushConstantRay pcRay; };
// clang-format on

//  
layout(std430, set = 1, binding = eAtrInfo) uniform _AtrInfoUniforms { AtrInfo ai; };
layout(set = 1, binding = eAtrSamplerLinear) uniform sampler AtrSampLin;
layout(set = 1, binding = eColormapSampler) uniform sampler colormapSampler;
layout(set = 1, binding = eAtrTexture) uniform texture3D atrTexture;
layout(set = 1, binding = eColormapTexture) uniform texture1D colormapTexture;
layout(location = 3) callableDataEXT rayLight cLight;


const int NBSAMPLES = 1;

vec4 mapColormap (float value);
vec3 calculateNormal (vec3 normalizedCoord);
vec3 computeDiffuseLighting(vec3 normal, vec3 cameraPosition, vec3 worldPosition, float shadow);
mat3 calculateTransform(vec3 N);
void render3dUIObjects(vec3 rayOrigin, vec3 rayDirection);
vec3 refineISOSurface(vec3 rayOrigin, vec3 rayDirection, float stepSize, inout vec3 p, float t);

#define ENABLED_ISOVALUE                      0
#define ENABLED_REFINEMENT         (1 && ENABLED_ISOVALUE)
#define ENABLED_DVR                (1 && !ENABLED_ISOVALUE)

#define ENABLED_DEBUG_AMBIENT_OCCLUSION       0


vec4 planeColor;

void main()
{
    // Initialize the random number
    uint seed = tea(gl_LaunchIDEXT.y * gl_LaunchSizeEXT.x + gl_LaunchIDEXT.x, pcRay.frame * NBSAMPLES);
    prd.seed  = seed;

    vec3 normal = vec3(0.f);
    prd.done                = 1;      
    prd.depth               = 0;
    prd.hitValue            = vec4(0.f, 0.f, 0.f ,0.f);
    prd.attenuation         = vec4(1.f, 1.f, 1.f, 1.f);
    prd.lastT               = -1.f;
    prd.hitCount            = 0;

    vec4 finalColor = vec4(0);
    float finalAO = 0;

    // show colormap
    ivec2 colormap_pos  = ivec2(gl_LaunchSizeEXT.x * 0.75f,  gl_LaunchSizeEXT.y * 0.95f);
    ivec2 colormap_size = ivec2(gl_LaunchSizeEXT.x * 0.2f, gl_LaunchSizeEXT.y * 0.025f);        // horizontal
    //ivec2 colormap_size = ivec2(gl_LaunchSizeEXT.x * 0.025f, gl_LaunchSizeEXT.y * 0.2f);      // vertical
    if( 
        //gl_LaunchIDEXT.x > colormap_pos.x && gl_LaunchIDEXT.x < (colormap_pos.x + colormap_size.x)  &&      // vertical
        gl_LaunchIDEXT.x < colormap_pos.x && gl_LaunchIDEXT.x > (colormap_pos.x - colormap_size.x)  &&      // horizontal
        gl_LaunchIDEXT.y < colormap_pos.y && gl_LaunchIDEXT.y > (colormap_pos.y - colormap_size.y)  )
    {
//        float v = float(gl_LaunchIDEXT.y - colormap_pos.y + colormap_size.y) / colormap_size.y;       // VERTICAL
        float v = float(gl_LaunchIDEXT.x - colormap_pos.x + colormap_size.x) / colormap_size.x;         // normalized coordinate of the current pixel in colormap bar // horizontal
        vec4 color =  texture(sampler1D(colormapTexture, colormapSampler), v);
        
        imageStore(image, ivec2(gl_LaunchIDEXT.xy), color);
        return;
    }

    for(int smpl = 0; smpl < NBSAMPLES; smpl++)
    {
        float r1 = rnd(seed);
        float r2 = rnd(seed);
        // Subpixel jitter: send the ray through a different position inside the pixel
        // each time, to provide antialiasing.
        vec2 subpixel_jitter    = pcRay.frame == 0 ? vec2(0.5f, 0.5f) : vec2(r1, r2);        
        const vec2 pixelCenter  = vec2(gl_LaunchIDEXT.xy) + subpixel_jitter;        
        const vec2 inUV         = pixelCenter / vec2(gl_LaunchSizeEXT.xy);
        vec2       d            = inUV * 2.0 - 1.0;
        
        vec4 origin             = uni.viewInverse * vec4(0, 0, 0, 1);
        vec4 target             = uni.projInverse * vec4(d.x, d.y, 1, 1);
        vec4 direction          = uni.viewInverse * vec4(normalize(target.xyz), 0);
        
        prd.rayOrigin           = origin.xyz;
        prd.rayDir              = direction.xyz;


        if(ai.hideClipPlane == 0) {
            render3dUIObjects(origin.xyz, direction.xyz);
        }

        vec3 minCorner = ai.minPoint.xyz;
        vec3 maxCorner = ai.minPoint.xyz + ai.dimension.xyz;
        
        // in which box side the ray from the origin enters and at which side exits
        vec3 s1, s2;
        vec3 n1 = vec3(-1.f, 0.f,  0.f);
        vec3 n2 = vec3( 0.f, -1.f,  0.f);
        vec3 n3 = vec3( 0.f,  0.f, -1.f);
        vec3 n4 = vec3( 1.f,  0.f,  0.f);
        vec3 n5 = vec3( 0.f,  1.f,  0.f);
        vec3 n6 = vec3( 0.f,  0.f,  1.f);
        
        float t1 = dot((minCorner - origin.xyz), n1) / dot (n1, direction.xyz);
        float t2 = dot((minCorner - origin.xyz), n2) / dot (n2, direction.xyz);
        float t3 = dot((minCorner - origin.xyz), n3) / dot (n3, direction.xyz);
        float t4 = dot((maxCorner - origin.xyz), n4) / dot (n4, direction.xyz);
        float t5 = dot((maxCorner - origin.xyz), n5) / dot (n5, direction.xyz);
        float t6 = dot((maxCorner - origin.xyz), n6) / dot (n6, direction.xyz);
        
        if(t1 > t4) { float tmp = t4; t4 = t1; t1 = tmp; }
        if(t2 > t5) { float tmp = t5; t5 = t2; t2 = tmp; }
        if(t3 > t6) { float tmp = t6; t6 = t3; t3 = tmp; }
    
        float tMin = max(t1, max(t2, t3));
        float tMax = min(t4, min(t5, t6));
       
         
    
        vec4 hitValues = vec4 (0);//pcRay.clearColor.xyz * 0.8, 1.f);
        float ao = 0.f;
       
        float tPlane = prd.tHit < 10000 ? prd.tHit : dot((ai.planePosition.xyz - origin.xyz), ai.planeNormal.xyz) / dot (ai.planeNormal.xyz, direction.xyz); // not missed 3d guide objects ? tHit of 3d objects : t (ray hits plane) = (P-O).N / N.D
        //tMax = min(tMax, tPlane);
        float planeSize = length(maxCorner - minCorner) * 1.5f;
        vec3 distanceToPlaneCenter = origin.xyz + tPlane * direction.xyz - ai.planePosition.xyz; // hit point distance to plane center
        bool ignoreRayTracing = false;
        
        vec3 entryPos = origin.xyz + tMin * direction.xyz;      // entry position of ray to 3d volume box
        vec3 exitPos = origin.xyz + tMax * direction.xyz;       // exit position of ray from 3d volume box
        
        float entryPosProj = dot(entryPos - ai.planePosition.xyz, ai.planeNormal.xyz);      // to see whether the volume is in front of clip plane or behind it, related to its normal
        float exitPosProj = dot(exitPos - ai.planePosition.xyz, ai.planeNormal.xyz);
        //bool stopRay = false;

        // if both entry and exit points are on the side of the clip plane that 
        // should be clipped
        if(entryPosProj > 0 && exitPosProj > 0) {
            ignoreRayTracing = true;       
        }
        
        // if entry point is on the side of plane that should be clipped
        if(entryPosProj > 0)
            tMin = max(tMin, tPlane);   // means tMin = tPlane
        
        // if exit point is on the side of plane that should be clipped 
        if(exitPosProj > 0)
            tMax = min(tMax, tPlane);   // means tMax = tPlane
            
//        if(abs(length(distanceToPlaneCenter) - planeSize / 2) < 2) {    // show plane border
//            //ignoreRayTracing = true;
//            tMax = min(tMax, tPlane);
//            //hitValues = vec4 (1.f, 0.f, 0.f, 0.f);
//        }
    
//        if(length(distanceToPlaneCenter) < 2 && dot(distanceToPlaneCenter, ai.planeNormal.xyz) == 0) { // show normal
//            ignoreRayTracing = true;
//            hitValues = vec4 (0.f, 0.f, 1.f, 0.f);
//        }
        if(prd.tHit < 10000 && prd.tHit > 0 && prd.tHit < tMax)     // means clipplane or its normal is in front of the volume, so render its frame or vector and dont render behind it
        {
            vec4 C = prd.hitValue;
            float ain = hitValues.a;
            vec3 Cin = hitValues.rgb;
            hitValues.rgb = Cin + (1 - ain) * C.rgb;
            hitValues.a = 1;
            ignoreRayTracing = true;
        }

        bool doRayMarching = tMax > tMin && tMin > 0 && !ignoreRayTracing;
        
        if(doRayMarching) {
            float stepSize = ai.stepSize; //0.5f;//length(maxCorner - minCorner) / 400.f;//(tMax - tMin) / 100.f;
            float t = tMin;
            
            for(int i=0; i<500 && t < tMax; ++i , t += stepSize) {
                vec3 p = origin.xyz + t * direction.xyz;
                vec3 normalizedCoord = (p - ai.minPoint.xyz) / ai.dimension.xyz;
                if(
                    normalizedCoord.x < 0 || normalizedCoord.x > 1 ||
                    normalizedCoord.y < 0 || normalizedCoord.y > 1 ||
                    normalizedCoord.z < 0 || normalizedCoord.z > 1)
                    continue;

                float attr = texture(sampler3D(atrTexture, AtrSampLin), normalizedCoord).x;//, clamp(normalizedCoord, vec3(0.0f), vec3(1.0f))).x; //
#if ENABLED_ISOVALUE
                if(attr >= ai.ISOValue) 
                {                    
                    if(ai.enableRefinement == 1) {
                        if(i > 0) {
                            normalizedCoord = refineISOSurface(origin.xyz, direction.xyz, stepSize, p, t);
                            if( normalizedCoord.x < 0 || normalizedCoord.x > 1 ||
                                normalizedCoord.y < 0 || normalizedCoord.y > 1 ||
                                normalizedCoord.z < 0 || normalizedCoord.z > 1)
                                continue;
                            attr = texture(sampler3D(atrTexture, AtrSampLin), normalizedCoord).x;//, clamp(normalizedCoord, vec3(0.0f), vec3(1.0f))).x;
                        }
                    }
                    normal = calculateNormal(normalizedCoord);

                    if(ai.useAmbinetOcclusion != 0)
                    {
                        mat3 tangentSpaceTransformation = calculateTransform(-normal);   // normal space transformation

                        const int aoSampleCount = 16;

                        for(int d=0; d<aoSampleCount; ++d) {
                            vec3 dir = normalize(tangentSpaceTransformation * ai.randomDirections[d].xyz); // bring directions from world space to tanget space
                            //if(dot(dir, -normal) < 0) {
                            //    dir = -dir;
                            //}                            
                            for(int s=1; s<500; ++s) {   // s = 2: to avoid self intersections
                                vec3 p0 = p + dir * s * stepSize;       // 
                                if(dot((p0 - ai.planePosition.xyz), ai.planeNormal.xyz) >= 0)   // point in the side of plane normal
                                    break;
                                normalizedCoord = (p0 - ai.minPoint.xyz) / ai.dimension.xyz;
                                if(
                                    normalizedCoord.x < 0 || normalizedCoord.x > 1 ||
                                    normalizedCoord.y < 0 || normalizedCoord.y > 1 ||
                                    normalizedCoord.z < 0 || normalizedCoord.z > 1)
                                    break;
                                float a = texture(sampler3D(atrTexture, AtrSampLin), normalizedCoord).x;
                                if(a >= ai.ISOValue) 
                                {       // occoluded
                                    ao += 1.f;
                                    break;
                                }
                            }
                        }
                        ao /= aoSampleCount; // occuluded
                    }

                    // shadow ray
                    float shadow = 0.f;
                    if(ai.shadowRay != 0)
                    {
                        vec3 dir = normalize(pcRay.lightDirection); //  (-vec3(1.f));//
                                                 
                        for(int s=5; s<500; ++s) {   // s = 1: to avoid self intersections
                            vec3 p0 = p + dir * s * stepSize;       // 
                            if(dot((p0 - ai.planePosition.xyz), ai.planeNormal.xyz) >= 0)
                                break;  
                            normalizedCoord = (p0 - ai.minPoint.xyz) / ai.dimension.xyz;
                            if(
                                normalizedCoord.x < 0 || normalizedCoord.x > 1 ||
                                normalizedCoord.y < 0 || normalizedCoord.y > 1 ||
                                normalizedCoord.z < 0 || normalizedCoord.z > 1)

                                break;
                            float a = texture(sampler3D(atrTexture, AtrSampLin), normalizedCoord).x;
                            if(a >= ai.ISOValue) {       // occoluded
                                shadow = 1.f;
                                break;
                            }                            
                        }
                    }
                           
                    vec3 diffuse = computeDiffuseLighting(normal, origin.xyz, p, shadow);
                     
                    vec3 ambientColor = ai.ambientColor.rgb;
                    float diffuseMultiplier = 0.5f;
                    float ambientMultiplier = 0.5f;

                    diffuse *= diffuseMultiplier;
                    ambientColor *= ambientMultiplier; 
                    diffuse += (1-ao) * ambientColor;
                                     
                    hitValues = mapColormap(attr) * vec4(diffuse, 1.f); // C
                    //hitValues.xyz = vec3(1-shadow);
                    hitValues.a = 1.0f;

                    break;
                }

#elif ENABLED_DVR
                normal = calculateNormal(normalizedCoord);
                
                if(ai.useAmbinetOcclusion != 0)
                {
                    mat3 tangentSpaceTransformation = calculateTransform(-normal);   // normal space transformation

                    const int aoSampleCount = 16;

                    for(int d=0; d<aoSampleCount; ++d) {
                        vec3 dir = normalize(tangentSpaceTransformation * ai.randomDirections[d].xyz); // bring directions from world space to tanget space
                       // if(dot(dir, -normal) < 0) {
                       //     dir = -dir;
                       // }
                        float collectedOcclusion = 0.f;
                        for(int s=2; s<32; ++s) {   // s = 2: to avoid self intersections
                            vec3 p0 = p + dir * s * stepSize;       // 
                             if(dot((p0 - ai.planePosition.xyz), ai.planeNormal.xyz) >= 0)   // point in the side of plane normal
                                    break;
                            normalizedCoord = (p0 - ai.minPoint.xyz) / ai.dimension.xyz;
                            if(
                                normalizedCoord.x < 0 || normalizedCoord.x > 1 ||
                                normalizedCoord.y < 0 || normalizedCoord.y > 1 ||
                                normalizedCoord.z < 0 || normalizedCoord.z > 1)

                                break;
                            float atr = texture(sampler3D(atrTexture, AtrSampLin), normalizedCoord).x;
                                                            
                            // Front-to-back strategy
                            float a = mapColormap(atr).a;
                                                                                      
                            collectedOcclusion = collectedOcclusion + (1 - collectedOcclusion) * a;

                            if(collectedOcclusion >= .95f) {
                                break;
                            }
                        }
                        ao += collectedOcclusion; 
                    }
                    ao /= aoSampleCount; // occluded
                }
                // shadow ray
                float shadow = 0.f;
                if(ai.shadowRay != 0)
                {
                    vec3 dir = normalize(pcRay.lightDirection); //  (-vec3(1.f));//
                    float collectedShadow = 0.f;                         
                    for(int s=5; s<500; ++s) {   // s = 1: to avoid self intersections
                        vec3 p0 = p + dir * s * stepSize;       // 
                        if(dot((p0 - ai.planePosition.xyz), ai.planeNormal.xyz) >= 0)
                            break;  
                        normalizedCoord = (p0 - ai.minPoint.xyz) / ai.dimension.xyz;
                                                
                        if(
                            normalizedCoord.x < 0 || normalizedCoord.x > 1 ||
                            normalizedCoord.y < 0 || normalizedCoord.y > 1 ||
                            normalizedCoord.z < 0 || normalizedCoord.z > 1)

                            break;
                        
                        float atr = texture(sampler3D(atrTexture, AtrSampLin), normalizedCoord).x;
                        float a = mapColormap(atr).a;
                                                                                  
                        collectedShadow = collectedShadow + (1 - collectedShadow) * a;
                        shadow = collectedShadow;
                        if(collectedShadow >= 1.f) {
                            shadow = 1.f;
                            break;
                        }                                                      
                    }
                }
                           
                vec3 diffuse = computeDiffuseLighting(normal, origin.xyz, p, shadow);
                
                vec3 ambientColor = ai.ambientColor.rgb;//vec3(1.f);
                float diffuseMultiplier = 0.5f;
                float ambientMultiplier = 0.8f;

                diffuse *= diffuseMultiplier;
                ambientColor *= ambientMultiplier; 
                diffuse += (1-ao) * ambientColor;
                // map colormap
                // Front-to-back strategy
                vec4 C = mapColormap(attr) * vec4(diffuse, 1.f); // C
                float a = C.a;
                float ain = hitValues.a;
                vec3 Cin = hitValues.rgb;
                hitValues.rgb = Cin + (1 - ain) * a * C.rgb;
                hitValues.a = ain + (1 - ain) * a;
                if(hitValues.a >= .95f) {
                    break;
                }
#endif // endif ENABLED_ISOVALUE/ENABLED_DVR
            } // end of raycasting for
        } // end of doRayMarching if

        if(prd.tHit < 10000 && (prd.tHit > tMin || !doRayMarching))
        {
            vec4 C = prd.hitValue;;
            float ain = hitValues.a;
            vec3 Cin = hitValues.rgb;
            hitValues.rgb = Cin + (1 - ain) * C.rgb;
            hitValues.a = 1;
        }

        // background color: clearColor
        vec4 C = vec4 (pcRay.clearColor.xyz * 0.8, 1.f);
        // float a = C.a; // a is 1.f;
        float ain = hitValues.a;
        vec3 Cin = hitValues.rgb;
        hitValues.rgb = Cin + (1 - ain) * C.rgb;
        hitValues.a = 1;
        
        finalColor += hitValues;
        finalAO += (1.0f - ao);
    }
    finalColor *= 1.f / NBSAMPLES;
    finalAO *= 1.f / NBSAMPLES;

#if ENABLED_DEBUG_AMBIENT_OCCLUSION
    finalColor = vec4(finalAO, finalAO, finalAO, 1);
#endif
    // Do accumulation over time
    if(pcRay.frame >= 0)
    {
      float a         = 1.0f / float(pcRay.frame + 1);
      vec3  old_color = imageLoad(image, ivec2(gl_LaunchIDEXT.xy)).xyz;
      imageStore(image, ivec2(gl_LaunchIDEXT.xy), vec4(mix(old_color, finalColor.rgb, a), 1.f));
    }
    else
    {
      // First frame, replace the value in the buffer
      imageStore(image, ivec2(gl_LaunchIDEXT.xy), vec4(finalColor.rgb, 1.f));
    }    
}

vec4 mapColormap (float value) {
    float normalizedValue = (value - ai.minAtrValue) / (ai.maxAtrValue - ai.minAtrValue);
    vec4 color =  texture(sampler1D(colormapTexture, colormapSampler), normalizedValue);
    return color;
}

vec3 calculateNormal (vec3 normalizedCoord) {
    //Computing normal with gradient of the surface
    vec3 normal;

    vec3 forwardStep  = vec3(1.f)  / ai.dimension.xyz;
    vec3 backwardStep = vec3(1.f) / ai.dimension.xyz;

    float f_XPlusDeltaX    = texture(sampler3D(atrTexture, AtrSampLin),  (normalizedCoord + vec3(forwardStep.x,  0.0f,  0.0f))).r;
    float f_XMinusDeltaX   = texture(sampler3D(atrTexture, AtrSampLin),  (normalizedCoord - vec3(backwardStep.x, 0.0f,  0.0f))).r;
    float f_YPlusDeltaY    = texture(sampler3D(atrTexture, AtrSampLin),  (normalizedCoord + vec3(0.0f,  forwardStep.y,  0.0f))).r;
    float f_YMinusDeltaY   = texture(sampler3D(atrTexture, AtrSampLin),  (normalizedCoord - vec3(0.0f, backwardStep.y,  0.0f))).r;
    float f_ZPlusDeltaZ    = texture(sampler3D(atrTexture, AtrSampLin),  (normalizedCoord + vec3(0.0f, 0.0f,   forwardStep.z))).r;
    float f_ZMinusDeltaZ   = texture(sampler3D(atrTexture, AtrSampLin),  (normalizedCoord - vec3(0.0f, 0.0f,  backwardStep.z))).r;

    vec3 n = vec3 (f_XPlusDeltaX - f_XMinusDeltaX, f_YPlusDeltaY - f_YMinusDeltaY, f_ZPlusDeltaZ - f_ZMinusDeltaZ) * 0.5f;
    if(dot(n, n) < 0.000001f)    // |n^2| < 0.001f
        normal = vec3(0.0f);
    else
    normal = normalize(n);
    return normal;
}

vec3 computeDiffuseLighting(vec3 normal, vec3 cameraPosition, vec3 worldPosition, float shadow) {
    // Point light
//    if(pcRay.lightType == 0)
//    {
//      vec3  lDir              = pcRay.lightPosition - cLight.inHitPosition;
//      float lightDistance     = length(lDir);
//      cLight.outIntensity     = pcRay.lightIntensity / (lightDistance * lightDistance);
//      cLight.outLightDir      = normalize(lDir);
//      cLight.outLightDistance = lightDistance;
//    }
//    else if(pcRay.lightType == 1) // spot light
//    {
//      vec3 lDir               = pcRay.lightPosition - cLight.inHitPosition;
//      cLight.outLightDistance = length(lDir);
//      cLight.outIntensity     = pcRay.lightIntensity / (cLight.outLightDistance * cLight.outLightDistance);
//      cLight.outLightDir      = normalize(lDir);
//      float theta             = dot(cLight.outLightDir, normalize(-pcRay.lightDirection));
//      float epsilon           = pcRay.lightSpotCutoff - pcRay.lightSpotOuterCutoff;
//      float spotIntensity     = clamp((theta - pcRay.lightSpotOuterCutoff) / epsilon, 0.0, 1.0);
//      cLight.outIntensity *= spotIntensity;
//    }
//    else  // Directional light
//    {
      cLight.outLightDir      = normalize(-pcRay.lightDirection);
      cLight.outIntensity     = 1.0;
      cLight.outLightDistance = 10000000;
//    }

    vec3 diffuse = vec3(0.f);
    // headlight
    if(ai.useHeadLight != 0) {
        vec3 LightDir = normalize(worldPosition - cameraPosition);
        diffuse      += computeDiffuse(LightDir, normalize(normal));
    }

    // Diffuse
    diffuse   += computeDiffuse(cLight.outLightDir, normalize(normal)) * (1-shadow);
    return diffuse;// * cLight.outIntensity;
}

mat3 calculateTransform(vec3 N)
{
  vec3 A = vec3(0.f, 1.f, 0.f);
  
  if(length(cross(A, N)) < 0.001f)
  {
    A = vec3(0.f, 0.0f, 1.0f);
  }

  vec3 X = cross(N, A);
  vec3 Y = cross(N, X);
  vec3 Z = N;

  X = normalize(X);
  Y = normalize(Y);
  Z = normalize(Z);

  //mat4 m0 = mat4(1.f);

  //m0.rotate(3.14159265f / 2.0f, vec3(1, 0, 0));

  //mat4 m1 = mat4(1.f);
  //m1.translate(P);


  mat3 m2 = mat3(vec3(X.x, Y.x, Z.x),
                 vec3(X.y, Y.y, Z.y),
                 vec3(X.z, Y.z, Z.z));
  //m2 = transpose(m2);

  /* mat3 m2 = mat3(X,
                 Y,
                 Z);
   */
  //nvmath::mat4f mat2 = nvmath::mat4f(X.x, X.y, X.z, 0, Y.x, Y.y, Y.z, 0, Z.x, Z.y, Z.z, 0, 0, 0, 0, 1);
//  mat4 scale = mat4(1.f);
//  scale.scale(s);

  //mat4 m3 = m2 ;
  return m2;
}

void render3dUIObjects(vec3 rayOrigin, vec3 rayDirection) {
    uint  rayFlags = gl_RayFlagsNoOpaqueEXT;
    float tMin     = 0.001;
    float tMax     = 10000.0;
    traceRayEXT(topLevelAS,     // acceleration structure
                rayFlags,       // rayFlags
                0xFF,           // cullMask
                0,              // sbtRecordOffset
                0,              // sbtRecordStride
                0,              // missIndex
                rayOrigin,     // ray origin
                tMin,          // ray min range
                rayDirection,  // ray direction
                tMax,        // ray max range
                0               // payload (location = 0)
        );
}

vec3 refineISOSurface(vec3 rayOrigin, vec3 rayDirection, float stepSize, inout vec3 p, float t) {
    vec3 lastPos = rayOrigin + (t-stepSize) * rayDirection;
    for (int j=0; j<10; j++) {
        vec3 midPos = (p + lastPos)/2.f;
        vec3 normalizedCoord = (midPos - ai.minPoint.xyz) / ai.dimension.xyz;
        float attr = texture(sampler3D(atrTexture, AtrSampLin), clamp(normalizedCoord, vec3(0.0f), vec3(1.0f))).x;
        if(attr >= ai.ISOValue) {
            p = midPos;
        } else {
            lastPos = midPos;
        }
    }
    return (p - ai.minPoint.xyz) / ai.dimension.xyz;
}